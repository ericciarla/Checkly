plumber::plumb(file='main.R')$run()
plumber::plumb(file='main.R')$run()
set.seed(10)
library(tidyverse)
library(SnowballC)
library(tensorflow)
library(keras)
library(caret)
library(tfdeploy)
library(rjson)
# Importing data
Fake <- read_csv("../datasets/Fake.csv")
True <- read_csv("../datasets/True.csv")
# Preproccessing
Fake <- Fake %>% select(title) %>% mutate(fake=1)
True <- True %>% select(title) %>% mutate(fake=0)
Total <- full_join(Fake,True)
Total <- sample_frac(Total, 1L) #Needed?
rm(Fake, True)
title_processing <- function(title){
new_title <- str_to_lower(title)
new_title <- str_replace_all(new_title,"\\$\\S+","dollar")
new_title <- str_replace_all(new_title,"\\d+","number")
new_title <- str_replace_all(new_title,"[^\\w|\\s]","")
new_title <- strsplit(new_title, " ")
new_title <- lapply(new_title,wordStem, language="en")
new_title <- lapply(new_title,trimws)
new_title <- new_title[new_title != ""]
return(new_title)
}
Total <- Total %>% rowwise() %>% mutate(title = title_processing(title))
# Get size of vocabulary
vocab <- c()
for(i in 1:nrow(Total)){
for (j in Total$title[[i]]) {
if(!(j %in% vocab)){
vocab <- c(vocab,j)
}
}
}
rm(i,j)
vocab_len <- length(vocab)
# Get max length of title
max_len <- 0
for(i in 1:nrow(Total)){
if(length(Total$title[[i]]) > max_len){
max_len <- length(Total$title[[i]])
}
}
rm(i)
# Tokenizing
tok <- text_tokenizer() %>% fit_text_tokenizer(vocab)
seq <- texts_to_sequences(tok, Total$title)
model_inputs <- pad_sequences(seq, maxlen = max_len)
labels <- Total$fake
# Splitting Test / Train
test_inds <- createDataPartition(labels, p = 0.2, list = F)
X_test <- model_inputs[test_inds, ]
y_test <- labels[test_inds]
X_train <- model_inputs[-test_inds, ]
y_train <- labels[-test_inds]
# Training
embedding_dim <- 64
input <- layer_input(shape=max_len)
embedding <- layer_embedding(
object = input,
input_dim = vocab_len,
output_dim = embedding_dim,
input_length = max_len,
name = "embedding"
)
gru <- layer_gru(
object = embedding,
units = embedding_dim,
name = "gru"
)
output <- layer_dense(
units = 1,
object = gru,
activation = 'sigmoid',
name = "output"
)
model <- keras_model(input,output)
model %>% compile(loss = "binary_crossentropy", optimizer = "adam", metrics="accuracy")
batchsize <- 32
ep <- 3
model %>% fit(
X_train,
y_train,
validation_split=0.2,
batch_size = batchsize,
epochs=ep
)
model %>% evaluate(X_test,y_test)
setwd("~/rprojs/newsClassifier")
library(plumber)
plumb(file='API.R')$run()
plumb(file='helloWorld/plumber.R')$run()
plumb(file='helloWorld/plumber.R')$run()
plumb(file='helloWorld/plumber.R')$run()
plumb(file='helloWorld/plumber.R')$run()
plumb(file='helloWorld/plumber.R')$run()
install.packages(c("backports", "BH", "boot", "broom", "callr", "cli", "clipr", "data.table", "dbplyr", "digest", "dplyr", "dslabs", "e1071", "ellipsis", "forcats", "foreach", "fs", "ggfortify", "ggplot2", "ggvis", "glue", "gower", "gtools", "haven", "hms", "htmltools", "httpuv", "httr", "infer", "iterators", "jsonlite", "KernSmooth", "knitr", "labeling", "later", "lattice", "lava", "lifecycle", "lubridate", "MASS", "Matrix", "mgcv", "mime", "modelr", "moderndive", "nlme", "nnet", "openssl", "pillar", "pkgbuild", "pkgload", "plyr", "prettyunits", "processx", "promises", "ps", "purrr", "Rcpp", "RCurl", "readr", "recipes", "remotes", "reshape2", "rlang", "rmarkdown", "rstudioapi", "rvest", "scales", "shiny", "skimr", "spatial", "SQUAREM", "stringi", "survival", "sys", "tibble", "tidyr", "tidyselect", "tinytex", "vctrs", "withr", "writexl", "xfun", "xml2", "xts", "yaml", "zoo"))
install.packages(c("backports", "BH", "boot", "broom", "callr", "cli", "clipr", "data.table", "dbplyr", "digest", "dplyr", "dslabs", "e1071", "ellipsis", "forcats", "foreach", "fs", "ggfortify", "ggplot2", "ggvis", "glue", "gower", "gtools", "haven", "hms", "htmltools", "httpuv", "httr", "infer", "iterators", "jsonlite", "KernSmooth", "knitr", "labeling", "later", "lattice", "lava", "lifecycle", "lubridate", "MASS", "Matrix", "mgcv", "mime", "modelr", "moderndive", "nlme", "nnet", "openssl", "pillar", "pkgbuild", "pkgload", "plyr", "prettyunits", "processx", "promises", "ps", "purrr", "Rcpp", "RCurl", "readr", "recipes", "remotes", "reshape2", "rlang", "rmarkdown", "rstudioapi", "rvest", "scales", "shiny", "skimr", "spatial", "SQUAREM", "stringi", "survival", "sys", "tibble", "tidyr", "tidyselect", "tinytex", "vctrs", "withr", "writexl", "xfun", "xml2", "xts", "yaml", "zoo"))
install.packages(c("backports", "BH", "boot", "broom", "callr", "cli", "clipr", "data.table", "dbplyr", "digest", "dplyr", "dslabs", "e1071", "ellipsis", "forcats", "foreach", "fs", "ggfortify", "ggplot2", "ggvis", "glue", "gower", "gtools", "haven", "hms", "htmltools", "httpuv", "httr", "infer", "iterators", "jsonlite", "KernSmooth", "knitr", "labeling", "later", "lattice", "lava", "lifecycle", "lubridate", "MASS", "Matrix", "mgcv", "mime", "modelr", "moderndive", "nlme", "nnet", "openssl", "pillar", "pkgbuild", "pkgload", "plyr", "prettyunits", "processx", "promises", "ps", "purrr", "Rcpp", "RCurl", "readr", "recipes", "remotes", "reshape2", "rlang", "rmarkdown", "rstudioapi", "rvest", "scales", "shiny", "skimr", "spatial", "SQUAREM", "stringi", "survival", "sys", "tibble", "tidyr", "tidyselect", "tinytex", "vctrs", "withr", "writexl", "xfun", "xml2", "xts", "yaml", "zoo"))
serve_savedmodel('savedmodel', browse = TRUE)
library(tfdeploy)
serve_savedmodel('savedmodel', browse = TRUE)
serve_savedmodel('savedmodel', browse = TRUE)
setwd("~/rprojs/newsClassifier")
plumber::plumb(file='r_api/plumber.R')$run()
